<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="spldoc_toolkit">
<title outputclass="spltoolkitname">Toolkit <tt>streamsx.protobuf 1.0.0.0</tt></title>
<refbody>
<section>
<p>
<xref href="../toolkits/toolkits.xml">Toolkits</xref> &gt; streamsx.protobuf 1.0.0.0</p>
</section>
<section>
<title outputclass="splhead-1">General Information</title>

<p>IBM Streams Protobuf Toolkit
</p>
<p>The <tt>streamsx.protobuf</tt> toolkit contains operators for interacting with serialized protocol buffer messages. It contains two conversion operators and two simple source operators.
</p>
<p>Currently, this toolkit only support <tt>proto2</tt> syntax.
</p>
<p>Examples can be found in the <tt>streamsx.protobuf.samples</tt> directory.
</p>
</section>
<section>
<title>Conversion operators
</title>
<p>
<ol>
<li> <tt>ProtobufParse</tt> takes a tuple with a <tt>blob</tt> field and emits a tuple matching the <tt>protoMessage</tt>    parameter type it is given.</li>
<li>
<p> <tt>ProtobufBuild</tt> takes a tuple as generated by the <tt>spl-schema-from-protobuf</tt> script (see below)    and emits a serialized version in the Protobuf serialization format as a blob.
</p></li>
</ol>
</p>
</section>
<section>
<title>Source operators
</title>
<p>
<ol>
<li> <tt>ProtobufTCPSource</tt> creates a TCP server that will accept connections which can pass 1 or    more Protobuf messages, each prefixed with a 4-byte record length.</li>
<li>
<p> <tt>ProtobufFileSource</tt> reads binary files that contain Protobuf messages, each prefixed with    a 4-byte record length.
</p></li>
</ol>
</p>
</section>
<section>
<title>Configuration
</title>
<p>The <tt>streamsx.protobuf</tt> toolkit requires the Protobuf libraries are installed on the compiling machine. Two environment variables are required: <tt>$STREAMSX_PROTOBUF_LIBPATH</tt> and <tt>$STREAMSX_PROTOBUF_INCLUDEPATH</tt>.
</p>
</section>
<section>
<title>Generating schemas
</title>
<p>This toolkit contains a script under <tt>streamsx.protobuf/bin</tt> called <tt>spl-schema-from-protobuf</tt>. This script will generate tuples in SPL to match the Protobuf messages in .proto files. This is required to use the conversion operators. <tt>ProtobufParse</tt> must emit the tuple generated by the script corresponding to the Protobuf message it is receiving, and <tt>ProtobufBuild</tt> must receive the tuple generated by the script corresponding to the Protobuf message it is sending.
</p>
<p>For all message and enum names, <tt>_pb</tt> is appended to the identifier. For all field names or enum values, <tt>_</tt> is appended to the identifier. An example can be seen in <tt>streamsx.protobuf.samples</tt>.
</p>
</section>
<section>
<title>Usage
</title>
<p>To use this toolkit, create an empty application. Place your <tt>.proto</tt> file inside <tt>&lt;application&gt;/impl</tt>.
</p>
<p>Call: <tt>&lt;path to streamsx.protobuf toolkit&gt;/bin/spl-schema-from-protobuf impl &lt;your protobuf file name&gt;</tt>
</p>
<p>This will generate the SPL schema to use with the conversion operators. Next, you will invoke one of the operators within your composite. If you have a Protobuf message named <tt>my.package.MyMessage</tt>, then given the file:
</p>
<p>
<codeblock>
<![CDATA[// MyMessage.proto

syntax = "proto2";

package my.package;

message MyMessage {
    required string field = 1;
}
]]></codeblock>

</p>
<p>The following SPL will be generated:
</p>
<p>
<codeblock>
<![CDATA[// my.package/MyMessage\_pb.spl

namespace my.package;

use my.package::*;

type MyMessage_pb = tuple<
    rstring field_
>;
]]></codeblock>

</p>
<p> ProtobufParse invocation
</p>
<p>To use the ProtobufParse operator, it is invoked like this:
</p>
<p>
<codeblock>
<![CDATA[stream<blob recordData> serializedRecords = ProtobufFileSource() {
    param
        file: "<binary file>";
}

stream<my.package::MyMessage_pb> myMessages = ProtobufParse(serializedRecords) {
    param
        dataAttribute: recordData;
        protoMessage: "my.package.MyMessage";
        protoDirectory: "impl";
        protoRootFile: "MyMessage.proto";
}
]]></codeblock>

</p>
<p> ProtobufBuild invocation
</p>
<p>To use the ProtobufBuild operator, it is invoked like this:
</p>
<p>
<codeblock>
<![CDATA[stream<my.package::MyMessage_pb> myMessages = Beacon() {
    param
        period: 1.0;
    output
        myMessages: field_ = "<value>";
}

stream<blob recordData> serializedRecords = ProtobufParse(myMessages) {
    param
        protoMessage: "my.package.MyMessage";
        protoDirectory: "impl";
        protoRootFile: "MyMessage.proto";
}
]]></codeblock>

</p>
</section>
<section>
<title>Under the hood
</title>
<p>How do the converters work?
</p>
<p>They utilize a grammar file in <tt>yapp</tt>, which is a Perl port of <tt>yacc</tt>. The grammar defines the <tt>proto2</tt> syntax according to the Google language specification sheet. The <tt>yapp</tt> grammar is compiled into a Perl module, which generates a parse tree containing all message and enum definitions within the file. For each import from the root file, this process is repeated until all files have been processed.
</p>
<p>The Build/Parse operators iterate through this parse tree to map Protobuf message values into and out of Streams tuples. At compile time, these operators run this parser to create the tree, and then they run the <tt>protoc</tt> command to generate the C++ that is the messages will use. The C++ is compiled into a shared object library named <tt>libcustomproto.so</tt>, which is stored in the application directory's <tt>impl/lib</tt>. This means that if more than one Build and/or Parse operator exists in the same composite, they cannot be compiled in parallel and they must used the same Protobuf definitions. Otherwise, race conditions will occur and one or both will be non-functional at run time.
</p>
<p>Variable mapping is generated recursively, so infinitely complex messages can be handled. There are two limitations: These operators cannot handle <tt>group</tt> fields or <tt>oneof</tt> fields. Oneof fields are planned for future implementation, but group fields have been deprecated by Google in favor of nested messages.
</p>
<p>Every available effort to ensure the readability of the generated code was made, as this makes debugging issues much easier. Feel free to take a look. However, all variable names are randomly generated to reduce the likelihood of a name collision. Name collisions are not checked beforehand, as the likelihood of not having a name collision in a message with 100 fields is (1-1/52^20)^100, which is infintessimally small.
</p>
<p>Some older versions of the <tt>protoc</tt> compiler do not require the first line to state <tt>syntax = "proto2";</tt>, but this parser requires the statement to be present regardless of the version of <tt>protoc</tt> installed.
</p>
<dl>
  <dlentry>
  <dt>Version</dt>
  <dd>1.0.0.0</dd>
  </dlentry>
  <dlentry>
  <dt>Required Product Version</dt>
  <dd>4.0.0.0</dd>
  </dlentry>
  <dlentry>
  <dt>Author</dt>
  <dd>IBMStreams</dd>
  </dlentry>
</dl>
</section>
<section>
  <title outputclass="splhead-1">Indexes</title>
  <dl>
    <dlentry><dt></dt><dd></dd></dlentry>
    <dlentry><dt><xref href="ix$Namespace.xml">Namespaces</xref></dt><dd></dd></dlentry>
    <dlentry><dt><xref href="ix$Operator.xml">Operators</xref></dt><dd></dd></dlentry>
  </dl>
</section>
<section>
  <title outputclass="splhead-1">Namespaces</title>
  <dl>
    <dlentry>
      <dt outputclass="splpart"><xref href="ns$streamsx.protobuf.xml">streamsx.protobuf</xref></dt>
      <dd></dd>
      <dd><dl><dlentry>
        <dt>Operators</dt>
        <dd>
<sl>
<sli><xref href="op$streamsx.protobuf$ProtobufBuild.xml">ProtobufBuild</xref></sli>
<sli><xref href="op$streamsx.protobuf$ProtobufFileSource.xml">ProtobufFileSource</xref></sli>
<sli><xref href="op$streamsx.protobuf$ProtobufParse.xml">ProtobufParse</xref></sli>
<sli><xref href="op$streamsx.protobuf$ProtobufTCPSource.xml">ProtobufTCPSource</xref></sli>
</sl>
        </dd>
      </dlentry></dl></dd>
     </dlentry>  </dl>
</section>
</refbody>
</reference>

